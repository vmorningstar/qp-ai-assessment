{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "039qkObM6zdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load required packages"
      ],
      "metadata": {
        "id": "8X_Kbh097LEm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7kYuhovU1396",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a081d349-e2fa-4f4e-8ea4-6e8badf33ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load required packages\n",
        "\n",
        "!pip install sentence-transformers\n",
        "!pip install -qU \\\n",
        "  pinecone-client \\\n",
        "  pinecone-datasets \\\n",
        "  sentence-transformers \\\n",
        "  PyPDF2 \\\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pdf link for pdf which i used to feed as document for this task\n",
        "pdf is stored in the same folder  with the name ct.pdf\n",
        "- https://www.cancer.org/content/dam/CRC/PDF/Public/6800.00.pdf"
      ],
      "metadata": {
        "id": "0gpqsyWZ7B-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sKsoQH267fGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing required modules\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from pinecone import Pinecone , ServerlessSpec , PodSpec\n",
        "\n",
        "\n",
        "def prepare_model(model_name):\n",
        "  '''\n",
        "      Load the pretrained model\n",
        "\n",
        "      params:\n",
        "        model_name : pretrained model name\n",
        "\n",
        "      return: Pretrained model object\n",
        "\n",
        "  '''\n",
        "\n",
        "  # load the model and return it\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  pretrained_model = SentenceTransformer(model_name, device=device)\n",
        "  return pretrained_model\n",
        "\n",
        "def get_embeddings(model , sentece_list):\n",
        "  # create the query vector\n",
        "  encoded_array = model.encode(sentece_list)\n",
        "  encoded_list = encoded_array.tolist()\n",
        "  return encoded_list\n",
        "\n",
        "def pdf_to_embeddings(pdf_path , pretrained_model ,min_page_no, max_page_no):\n",
        "  '''\n",
        "      convert pdf text sentences to embeddings\n",
        "\n",
        "      params:\n",
        "        pdf_path : path of pdf\n",
        "        pretrained_model: pretrained model object\n",
        "        min_page_no: initial page no\n",
        "        max_page_no: final page no\n",
        "\n",
        "      return: embedding list with required metadata\n",
        "\n",
        "  '''\n",
        "  reader = PdfReader(pdf_path)\n",
        "  records_to_search = []\n",
        "  sentece_list_meta = []\n",
        "  sentence_num = 0\n",
        "\n",
        "  for page_ind , page in  enumerate(reader.pages[min_page_no-1:max_page_no]):\n",
        "    # extracting text from page\n",
        "    text = page.extract_text()\n",
        "    paragraph_list = text.split('.\\n')\n",
        "\n",
        "    # create sentece embeddings and respected meta data\n",
        "    for index_para, text_para in enumerate(paragraph_list):\n",
        "      para_id = f'Paragraph_{page_ind}_{index_para}'\n",
        "      # print(f'Paragraph_{page_ind}_{index_para}' ,text_para )\n",
        "      sentece_text_list = text_para.replace('\\n','').split('. ')\n",
        "      sentece_embedding_list = get_embeddings(pretrained_model , sentece_text_list)\n",
        "      for sentence_ind ,  sentence_val in enumerate(sentece_text_list):\n",
        "        metadata_dict = {}\n",
        "        sentence_value_dict = {}\n",
        "        id = f'sentence_{sentence_num}'\n",
        "\n",
        "        sentence_value_dict['id']=id\n",
        "        sentence_value_dict['values']=sentece_embedding_list[sentence_ind]\n",
        "\n",
        "        metadata_dict['page_index'] =min_page_no + page_ind\n",
        "        metadata_dict['sentence_text'] = sentece_text_list[sentence_ind]\n",
        "        metadata_dict['paragraph_id'] = para_id\n",
        "        sentence_value_dict['metadata'] = metadata_dict\n",
        "\n",
        "        sentece_list_meta.append(sentence_value_dict)\n",
        "        sentence_num += 1\n",
        "\n",
        "  print(f'embeddings and metadata for text in page {min_page_no} to page {max_page_no} are generated')\n",
        "  return sentece_list_meta\n",
        "\n",
        "def create_pinecone_index(api_key , index_name , embedding_dim , similarity_metric):\n",
        "  '''\n",
        "      create pinecone vector database\n",
        "\n",
        "      params:\n",
        "        api_key : account api key\n",
        "        index_name: database index name\n",
        "        embedding_dim: each vector size\n",
        "        similarity_metric: similarity metric for search\n",
        "\n",
        "      return: database instance\n",
        "\n",
        "  '''\n",
        "  # create the pinecone instance with provided vector size and similarity metric\n",
        "  pc = Pinecone(api_key=api_key)\n",
        "  active_indexes = [i['name'] for  i  in  pc.list_indexes()]\n",
        "  if index_name in active_indexes:\n",
        "    pc.delete_index(index_name)\n",
        "\n",
        "  pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=embedding_dim,\n",
        "    metric=similarity_metric, # cosine\n",
        "    spec=PodSpec(\n",
        "      environment=\"gcp-starter\"\n",
        "    )\n",
        "  )\n",
        "\n",
        "  index = pc.Index(index_name)\n",
        "  return index\n",
        "\n",
        "def generate_question_embedding(pretrained_model , prompt):\n",
        "    '''\n",
        "      create embeddings for question text\n",
        "\n",
        "      params:\n",
        "        pretrained_model : pretrained model object\n",
        "        prompt: question text\n",
        "\n",
        "      return: qustion embeddings\n",
        "\n",
        "    '''\n",
        "    #create question embedding from pretrained model\n",
        "    que_emb = get_embeddings(pretrained_model , [prompt])\n",
        "    que_emb = que_emb[0]\n",
        "    return que_emb\n",
        "\n",
        "def search_topk_similar_records(query_vector ,  pinecone_index , top_k):\n",
        "    '''\n",
        "      fetch the top results with respect schemantic similarity\n",
        "\n",
        "      params:\n",
        "        query_vector : question embedding vector\n",
        "        pinecone_index: vector database where document text embeddings are stored\n",
        "\n",
        "      return: top k results with metadata\n",
        "\n",
        "    '''\n",
        "    # search topk result with the type of score set in vector dataset\n",
        "    results = pinecone_index.query( vector = query_vector , top_k = top_k , include_values=True ,  include_metadata=True)\n",
        "    return results\n",
        "\n",
        "def store_document_to_dataset(document_path , pretrained_model , pinecone_index , min_page_no , max_page_no ):\n",
        "    '''\n",
        "      create the embeddings for document and store in pinecone blank dataset\n",
        "\n",
        "      params:\n",
        "        document_path : path for pdf file\n",
        "        pretrained_model : pretrained model object\n",
        "        pinecone_index: vector database where document text embeddings are stored\n",
        "        min_page_no: initial page no\n",
        "        max_page_no: final page no\n",
        "\n",
        "      return: top k results with metadata\n",
        "\n",
        "    '''\n",
        "    # convert pdf to embeddings\n",
        "    vectors_metadata = pdf_to_embeddings(pdf_path , pretrained_model ,min_page_no , max_page_no  )\n",
        "\n",
        "    # fit document embeddings in vector database\n",
        "    pinecone_index.upsert(\n",
        "      vectors=vectors_metadata\n",
        "    )\n",
        "\n",
        "\n",
        "# Define a function to generate a response to the user's query\n",
        "def q_and_a_chatbot(question_text, pretrained_model , database_loaded_index , top_k , similarity_threshould = 0.3):\n",
        "    '''\n",
        "      provide the top k answers according to similarity metric\n",
        "      provide message if not found any sentence above certain threshould\n",
        "\n",
        "      params:\n",
        "        question_text : text of the question\n",
        "        pretrained_model : pretrained model object\n",
        "        database_loaded_index: vector database instance where document text embeddings are stored\n",
        "        top_k: no of top responses\n",
        "\n",
        "      return: top k results with required structure\n",
        "\n",
        "    '''\n",
        "    result_dict_list =[]\n",
        "\n",
        "    # create the question embbeding\n",
        "    query_vector = generate_question_embedding(pretrained_model , question_text)\n",
        "\n",
        "    # get the most similar vectors to the user's query vector\n",
        "    top_similar_results = search_topk_similar_records(query_vector ,  pinecone_index , top_k)\n",
        "\n",
        "    # instruction if blank array produced\n",
        "    if top_similar_results['matches'] == []:\n",
        "      print('Rerun the cell and reduce the top k number, as pinecode free version sometimes give blank result')\n",
        "      return result_dict_list\n",
        "\n",
        "\n",
        "    top_similar_answers = [{'score':i['score'],'metadata':i['metadata']} for i in top_similar_results['matches']]\n",
        "    score_arr = [i['score'] for i in top_similar_results['matches']]\n",
        "\n",
        "    # if no schemantic similarity present in the sentence likely there is no answer in it\n",
        "    if max(score_arr) < similarity_threshould:\n",
        "      print(\"I don't know the answer.\")\n",
        "      return result_dict_list\n",
        "\n",
        "    # return top k results and thier scores\n",
        "\n",
        "    for result_ind , result_dict in enumerate(top_similar_results['matches']):\n",
        "        result_dict_list.append({'rank':int(result_ind+1) , 'score': result_dict['score'] , 'response_text':result_dict['metadata']['sentence_text'] })\n",
        "\n",
        "    return result_dict_list"
      ],
      "metadata": {
        "id": "jLWUbK4k2HM6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qd3-Jd8F74LW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the document devide it into sentences and store document embeddings in pinecone database"
      ],
      "metadata": {
        "id": "DtdIegRiCEO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# context level info\n",
        "pdf_path = 'ct.pdf'\n",
        "min_page_no = 5\n",
        "max_page_no = 7\n",
        "\n",
        "# database level info\n",
        "index_name = 'closeddomainqanda'\n",
        "api_key='01d05f63-7f48-4f3a-b1be-92cab459a713'\n",
        "\n",
        "#ebedding size of pretrained model\n",
        "embedding_dim= 384\n",
        "\n",
        "# model which used to create embeddings , i choose multi-qa-MiniLM-L6-cos-v1 because it is trained for q and a task, so it will produce better embeddings with respect to our task objective\n",
        "# model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "model_name = 'sentence-transformers/multi-qa-MiniLM-L6-cos-v1'\n",
        "\n",
        "# choose dotproduct to select most relative text , available scores in pinecone are ['cosine', 'euclidean', 'dotproduct']\n",
        "similarity_metric=\"dotproduct\"\n",
        "\n",
        "# choose the minimum score threshould for valid answers\n",
        "similarity_threshould = 0.3\n",
        "\n",
        "# load the pretrained model\n",
        "pretrained_model = prepare_model(model_name)\n",
        "\n",
        "#create blank vector database\n",
        "pinecone_index = create_pinecone_index(api_key , index_name , embedding_dim , similarity_metric)\n",
        "\n",
        "#create and store document embeddings to search the answers of questions in created vector database\n",
        "store_document_to_dataset(pdf_path , pretrained_model , pinecone_index , min_page_no , max_page_no )"
      ],
      "metadata": {
        "id": "v5w2R_9F2sVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fff2cb-f6f7-49fb-d7c3-4aeca3782b2f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings and metadata for text in page 5 to page 7 are generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions and Answers\n",
        "\n",
        "### Example questions and top k responses"
      ],
      "metadata": {
        "id": "dRVMw-6qCL9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Good example where answers are present"
      ],
      "metadata": {
        "id": "sbI2KEZyCbMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ask questions for which text is availabe in document which having similarity score above certain threshould\n",
        "question_text = 'how many patients with the same type of cancer get the new treatment in a phase II study ?'\n",
        "top_k_searches = 5\n",
        "# get the top responses from the document wich is above the defined threshould\n",
        "# you can also tune the top k search number and if you dont get any answer you can lower the similarity_threshould\n",
        "q_and_a_chatbot(question_text, pretrained_model , pinecone_index , top_k_searches , similarity_threshould)"
      ],
      "metadata": {
        "id": "eTlMzsS42xhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6594598-18bb-4471-ef6d-1c03abb5f045"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rank': 1,\n",
              "  'score': 0.730267704,\n",
              "  'response_text': 'American Cancer Society cancer.org | 1.800.227.2345 ____________________________________________________________________________________A group of 25 to 100 patients with the same type of cancer get the new treatment ina phase II study'},\n",
              " {'rank': 2,\n",
              "  'score': 0.631570339,\n",
              "  'response_text': 'Phase II clinical trials: Does the treatment work?\\xa0\\xa0If a new treatment is found to be safe in phase I clinical trials, a phase II clinical trial isdone to see if it works in certain types of cancer'},\n",
              " {'rank': 3,\n",
              "  'score': 0.627096653,\n",
              "  'response_text': 'These groups mayget different doses or get the treatment in different ways to see which provides thebest balance of safety and response.●Placebos (inactive treatments) are not\\xa0used in phase II trials.●Phase II studies may be done at major cancer centers, community hospitals oreven doctors’ offices.●Larger numbers of patients get the treatment in phase II trials, so less common sideeffects may be seen'},\n",
              " {'rank': 4,\n",
              "  'score': 0.626983166,\n",
              "  'response_text': 'If enough patients benefit from the treatment, and the side effectsaren’t too bad, phase III clinical trials are begun'},\n",
              " {'rank': 5,\n",
              "  'score': 0.615968347,\n",
              "  'response_text': 'Sometimes people choose to join phase I trials when all other treatmentoptions have already been tried'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bad exambple where answer is not present in document"
      ],
      "metadata": {
        "id": "fmgFC2FUGfdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ask questions which are out of context\n",
        "question_text = 'how many states are present in india'\n",
        "top_k_searches = 5\n",
        "q_and_a_chatbot(question_text, pretrained_model , pinecone_index , top_k_searches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDbgHOzHCRiq",
        "outputId": "97c1747c-c38c-4690-f815-d3e34770cb2a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know the answer.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}